{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea21024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/ahornachowdhury/anaconda3/lib/python3.11/site-packages (4.8.1.78)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/ahornachowdhury/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195bf840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # OpenCV\n",
    "import os # File paths\n",
    "import time # Breaks between image collection\n",
    "import uuid # Name image files with unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20e8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'Tensorflow/workspace/images/collectedimages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b58e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = ['hello', 'thankyou', 'yes', 'no', 'iloveyou']\n",
    "number_images = 15 # 15 images will be collected for each sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98fe67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image for hello\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Collecting image for thankyou\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Collecting image for yes\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Collecting image for no\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Collecting image for iloveyou\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n",
      "Captured\n"
     ]
    }
   ],
   "source": [
    "for label in image_labels:\n",
    "    current_dir = os.getcwd()\n",
    "    label_dir = \"Tensorflow/workspace/images/collectedimages/\" + label # Create directory for each label\n",
    "    path = os.path.join(current_dir, label_dir)\n",
    "    os.mkdir(path)\n",
    "    capture_image = cv2.VideoCapture(0) # Start video capture\n",
    "    print(f\"Collecting image for {label}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    for image_num in range(number_images):\n",
    "        # Setup image capture\n",
    "        ret, frame = capture_image.read()\n",
    "        file_name = label + \".\" + str(uuid.uuid1()) + \".jpg\"\n",
    "        image_name = os.path.join(IMAGES_PATH, label, file_name)\n",
    "        cv2.imwrite(image_name, frame) # Write image to directory\n",
    "        print(\"Captured\")\n",
    "        cv2.imshow('frame', frame) # Show captured image\n",
    "        time.sleep(2)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    capture_image.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b04b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c18a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/HumanSignal/labelImg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9455b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5==5.15.2 in /Users/ahornachowdhury/anaconda3/lib/python3.11/site-packages (5.15.2)\r\n",
      "Requirement already satisfied: lxml in /Users/ahornachowdhury/anaconda3/lib/python3.11/site-packages (4.9.3)\r\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /Users/ahornachowdhury/anaconda3/lib/python3.11/site-packages (from pyqt5==5.15.2) (12.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5==5.15.2 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069b43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahornachowdhury/Documents/projects/ASL_detection/Tensorflow/labelImg/labelImg.py:73: DeprecationWarning: sipPyTypeDict() is deprecated, the extension module should use sipPyTypeDictRef() instead\n",
      "  class MainWindow(QMainWindow, WindowMixin):\n",
      "Loading setting failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahornachowdhury/Documents/projects/ASL_detection/Tensorflow/labelImg/labelImg.py\", line 1277, in closeEvent\n",
      "    settings.save()\n",
      "  File \"/Users/ahornachowdhury/Documents/projects/ASL_detection/Tensorflow/labelImg/libs/settings.py\", line 26, in save\n",
      "    pickle.dump(self.data, f, pickle.HIGHEST_PROTOCOL)\n",
      "SystemError: PY_SSIZE_T_CLEAN macro must be defined for '#' formats\n"
     ]
    }
   ],
   "source": [
    "!python3 Tensorflow/labelImg/labelImg.py # Use labelImg to label and annotate the captured images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
